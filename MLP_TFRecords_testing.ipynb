{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tpu.python.tpu import tpu_config\n",
    "from tensorflow.contrib.tpu.python.tpu import tpu_estimator\n",
    "from tensorflow.contrib.tpu.python.tpu import tpu_optimizer\n",
    "import pdb\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_DIR = './MLP/model_2'\n",
    "DATA_DIR = './MLP_data'\n",
    "\n",
    "prefetch_buffer_size = 128\n",
    "num_files_infeed = 16\n",
    "shuffle_buffer_size = 512\n",
    "num_parallel_calls = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(\n",
    "        DATA_DIR, 'MLP_data_test*')\n",
    "\n",
    "dataset = tf.data.Dataset.list_files(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MLP_data/MLP_data_test.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./MLP_data/MLP_data_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MLP_data/MLP_data_test.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!ls $file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Input(object):\n",
    "  \"\"\"Wrapper class that acts as the input_fn to TPUEstimator.\"\"\"\n",
    "\n",
    "  def __init__(self, is_training=True, is_eval=True, data_dir=None):\n",
    "    self.is_eval = is_eval\n",
    "    self.is_training = is_training\n",
    "    self.data_dir = data_dir if data_dir else DATA_DIR\n",
    "\n",
    "  def dataset_parser(self, value):\n",
    "    \"\"\"Parse an Imagenet record from value.\"\"\"\n",
    "    keys_to_features = {\n",
    "        'X': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'y': tf.FixedLenFeature(shape=[1], dtype=tf.int64)            \n",
    "    }\n",
    "    parsed = tf.parse_single_example(value, keys_to_features)\n",
    "    X = tf.decode_raw(parsed['X'], tf.float32)\n",
    "    X = tf.reshape(X, [10000])\n",
    "    \n",
    "    y = tf.cast(parsed['y'], tf.int64)\n",
    "    return X, y\n",
    "\n",
    "  def __call__(self, params):\n",
    "    \"\"\"Input function which provides a single batch for train or eval.\"\"\"\n",
    "    # Retrieves the batch size for the current shard. The # of shards is\n",
    "    # computed according to the input pipeline deployment. See\n",
    "    # `tf.contrib.tpu.RunConfig` for details.\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    # Shuffle the filenames to ensure better randomization\n",
    "    file_pattern = os.path.join(\n",
    "        self.data_dir, 'MLP_data_train*' if self.is_training \n",
    "        else 'MLP_data_test*' )\n",
    "    dataset = tf.data.Dataset.list_files(file_pattern)\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    \n",
    "    if self.is_training:\n",
    "      dataset = dataset.shuffle(buffer_size=128)  # 1024 files in dataset\n",
    "\n",
    "    if self.is_training:\n",
    "      dataset = dataset.repeat()\n",
    "\n",
    "    def prefetch_dataset(filename):\n",
    "      buffer_size =  prefetch_buffer_size\n",
    "      dataset = tf.data.TFRecordDataset(filename, buffer_size=buffer_size)\n",
    "      return dataset\n",
    "\n",
    "    dataset = dataset.apply(\n",
    "        tf.contrib.data.parallel_interleave(\n",
    "            prefetch_dataset, cycle_length= num_files_infeed,\n",
    "            sloppy=True))\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        self.dataset_parser,\n",
    "        num_parallel_calls=num_parallel_calls)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "    dataset = dataset.apply(\n",
    "        tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
    "\n",
    "    dataset = dataset.prefetch(2)  # Prefetch overlaps in-feed with training\n",
    "    images, labels = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    if self.is_training or self.is_eval:\n",
    "          return images, labels\n",
    "    else:\n",
    "          return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = MLP_Input(is_training=False)\n",
    "X, y = my_data({'batch_size':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  valX, valy = sess.run([X, y])\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000) [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(10, 10000) [[1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(10, 10000) [[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(10, 10000) [[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(10, 10000) [[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_path = './MLP_data/MLP_data_test.tfrecords'  # address to save the hdf5 file\n",
    "with tf.Session() as sess:\n",
    "    feature =  {\n",
    "        'X': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'y': tf.FixedLenFeature(shape=[1], dtype=tf.int64)            \n",
    "    }\n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['X'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['y'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [10000])\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "    images, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n",
    "    \n",
    "        # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(5):\n",
    "        img, lbl = sess.run([images, labels])\n",
    "        print(img.shape, lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68277508, -1.70158255,  0.1727289 , ...,  0.10917469,\n",
       "        -2.40945673, -1.14211142],\n",
       "       [-0.52076739,  1.81326783, -0.51520407, ..., -0.57771862,\n",
       "         1.21164513,  1.26358306],\n",
       "       [-0.634489  ,  0.23487876, -1.58474731, ...,  2.48326564,\n",
       "        -0.64282036,  1.32642758],\n",
       "       ..., \n",
       "       [ 0.47943571, -0.19249211, -1.13439512, ..., -0.14228664,\n",
       "        -0.03568394,  0.53308493],\n",
       "       [-0.41281357,  0.07613051, -0.0979723 , ..., -0.198423  ,\n",
       "         0.7150836 , -0.40859175],\n",
       "       [ 0.82969844,  1.00123513,  1.00835955, ..., -0.66160816,\n",
       "         0.07516851,  0.2780641 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
